
# ğŸ“ Automated Essay Grading API

This project is a full-featured, containerized FastAPI application that uses OpenAI's language models to automatically grade student essays based on a customizable rubric. It includes an SDK, batch grading script, continuous integration, and optional GitHub Actions testing support.

## ğŸš€ Features

- ğŸ”§ **FastAPI** backend for real-time grading
- ğŸ§  **LLM-based scoring** using OpenAI's API
- ğŸ“‚ **Batch grading support** for PDF and Word documents
- ğŸ”’ **API key authentication**
- ğŸ§ª **Pytest test suite** with optional CI token skipping
- ğŸ³ **Dockerized** for portability and reproducibility
- ğŸ“„ **Markdown docs** and `.env` configuration
- ğŸ“ˆ **CSV or pickle** output with structured rubric scores

---

## ğŸ“ Project Structure

```
review-classifier-deploy/
â”œâ”€â”€ api/                # FastAPI app
â”‚   â”œâ”€â”€ main.py         # API entrypoint
â”‚   â”œâ”€â”€ grader.py       # Core grading logic
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ batch_grade.py  # Batch grading script for essays
â”œâ”€â”€ essays/             # Student folders with PDFs/DOCs
â”œâ”€â”€ tests/              # Pytest-based test suite
â”œâ”€â”€ .env                # API keys and config variables
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ Dockerfile          # Image definition
â”œâ”€â”€ Makefile            # Automation for linting/testing
â”œâ”€â”€ README.md           # This file
â””â”€â”€ .github/workflows/
    â””â”€â”€ ci.yml          # GitHub Actions test workflow
```

---

## ğŸ“¦ Installation

### 1. Clone the repository

```bash
git clone https://github.com/your-username/review-classifier-deploy.git
cd review-classifier-deploy
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Set up your environment

Create a `.env` file:

```bash
cp .env.example .env
```

Edit `.env` to include:

```env
OPENAI_API_KEY=your_openai_api_key
API_KEY=your_local_api_key
```

---

## ğŸ³ Run the API (Docker)

```bash
docker build -t essay-grader .
docker run -p 8000:8000 --env-file .env essay-grader
```

The API will be available at `http://localhost:8000`.

---
---
## Run the API (Local)
```bash
make install     # once per machine
make run         # starts the API
make grade       # evaluates essays
make print       # get csv of simplified grades
```
The API will be available at `http://localhost:8000`.

## ğŸ§ª Run Tests

To run tests **without calling the OpenAI API**:

```bash
SKIP_OPENAI_CALLS=true make test
```

To test normally (requires OpenAI key):

```bash
make test
```

---

## ğŸ—ƒ Batch Grading from Essays Folder

### Folder format

Each folder in the `essays/` directory should be named after the student and contain their PDF or DOCX files.

```
essays/
â”œâ”€â”€ smith--jane/
â”‚   â””â”€â”€ smith_jane_essay.docx
â”œâ”€â”€ lee--chris/
â”‚   â””â”€â”€ lee_chris_essay.pdf
```

### Run the batch grader

```bash
make grade
make print
```

This will:

- Extract text from each document
- Send it to the API
- Return rubric scores and feedback
- Save the results as a `.pkl` file (preserving types)
- Make a nicely formatted CSV file simplified with student names and total scores
- Make a histogram of the scores.
---

## ğŸ“Š Output Example

```python
import pandas as pd
import pickle

with open("graded_essays.pkl", "rb") as f:
    data = pickle.load(f)

df = pd.DataFrame(data)
print(df.head())
```

| student        | filename         | Accuracy_score | Argument_score | ... | Mechanics_score |
|----------------|------------------|----------------|----------------|-----|-----------------|
| smith--jane    | jane_essay.pdf   | 3              | 2              | ... | 3               |
| lee--chris     | chris_essay.docx | 2              | 2              | ... | 2               |

---

## âš™ï¸ CI/CD with GitHub Actions

Tests automatically run on pull requests and pushes to `main`. The CI skips OpenAI calls unless the token is explicitly provided in GitHub Secrets (`OPENAI_API_KEY`).

---

## ğŸ” Authentication

All grading requests require an API key:

```http
POST /grade
x-api-key: your_local_api_key
```

---

## ğŸ“Œ Future Improvements

- Add user roles and dashboards
- Integrate rubric editing UI
- Caching / deduplication of essay scores
- Web front-end for drag-and-drop batch grading

---

## ğŸ§  Example Use Cases

- Automating high school or college writing assessment
- Portfolio evidence collection for education programs
- Rapid SLO-based program evaluation

---

## ğŸ“„ License

MIT License


## How to run
```
make install     # once per machine
make run         # starts the API
make grade       # evaluates essays
make print       # get csv of simplified grades
```

## Sample Rubric Entry
```
{
  "rubric": {
    "Accuracy": {
      "3": "Factual content is correct and comprehensive.",
      "2": "Mostly correct but with minor inaccuracies.",
      "1": "Major factual errors or missing key information."
    },
    "Argument": {
      "3": "Clear, well-supported argument throughout.",
      "2": "Argument present but inconsistently supported.",
      "1": "Argument is unclear or missing."
    },
    "Conclusions & Extensions": {
      "3": "Draws insightful conclusions or goes beyond prompt.",
      "2": "Basic conclusions relevant to the prompt.",
      "1": "No conclusion or completely off-topic."
    },
    "Mechanics": {
      "3": "Flawless grammar, spelling, and punctuation.",
      "2": "Some errors that don't impede understanding.",
      "1": "Frequent or distracting language issues."
    }
  }
}
```